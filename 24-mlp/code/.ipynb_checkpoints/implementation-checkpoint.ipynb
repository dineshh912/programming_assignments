{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4c5179-09ab-43cf-b714-d730687a1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cbadabb-5c16-49d9-80dd-a6bc7b05be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data.\n",
    "# training data\n",
    "train_data = np.genfromtxt(\"optdigits_train.txt\",delimiter=\",\")\n",
    "train_x = train_data[:,:-1]\n",
    "train_y = train_data[:,-1].astype('int')\n",
    "\n",
    "# validation data\n",
    "valid_data = np.genfromtxt(\"optdigits_valid.txt\",delimiter=\",\")\n",
    "valid_x = valid_data[:,:-1]\n",
    "valid_y = valid_data[:,-1].astype('int')\n",
    "\n",
    "# test data\n",
    "test_data = np.genfromtxt(\"optdigits_test.txt\",delimiter=\",\")\n",
    "test_x = test_data[:,:-1]\n",
    "test_y = test_data[:,-1].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9c2014-047f-4e59-8500-79459c00b1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 3., ..., 2., 0., 0.],\n",
       "       [0., 0., 4., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 7., ..., 2., 0., 9.],\n",
       "       [0., 0., 7., ..., 0., 0., 9.],\n",
       "       [0., 0., 4., ..., 8., 0., 9.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497d22c5-2753-4243-9e2a-e6c92c4d3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  3., ..., 13.,  2.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  4.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  7., ..., 10.,  2.,  0.],\n",
       "       [ 0.,  0.,  7., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ..., 15.,  8.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2bf802-cc98-424a-bbdd-59683187de23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b15f4ae-e258-4dc6-8216-448394b7c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data,mean=None,std=None):\n",
    "    # normalize the data to have zero mean and unit variance (add 1e-15 to std to avoid numerical issue)\n",
    "    if mean is not None:\n",
    "        # directly use the mean and std precomputed from the training data\n",
    "        data = (data - mean) / (std + 1e-15)\n",
    "        return data\n",
    "    else:\n",
    "        # compute the mean and std based on the training data\n",
    "        # mean = std = 0 # placeholder\n",
    "        mean = data.mean(axis=0)\n",
    "        std = data.std(axis=0)\n",
    "        data = (data - mean) / (std + 1e-15)\n",
    "        \n",
    "        return data, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b1475e-3500-4582-865c-dbd5a5247396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "train_x, mean, std = process_data(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6d334c-6491-4826-a288-205b55bb65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(label):\n",
    "    # convert the labels into one-hot vector for training\n",
    "    # Creating array of 0's of required size. then replace 0 with 1\n",
    "    # at required place. \n",
    "    one_hot = np.zeros([len(label),10])\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        one_hot[i][label[i]] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b5b7c3d-666b-4613-a372-b7ca50609e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process training labels into one-hot vectors\n",
    "train_y = process_label(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f44ea39-3aca-40fc-bf07-5c31e7f645c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    # implement the hyperbolic tangent activation function for hidden layer\n",
    "    # You may receive some warning messages from Numpy. No worries, they should not affect your final results\n",
    "\n",
    "    f_x = (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    return f_x\n",
    "\n",
    "def softmax(x):\n",
    "    # implement the softmax activation function for output layer\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71584f88-a0b8-4200-91ea-ff7203683eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5b1a5-38ef-4f59-a5ac-e5d0c7639dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both train and test data is ready for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ad84cf-3a1b-4ea4-84ce-cc887146ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_num_hid = [4,8,16,20,24] # no of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b60007b8-eb79-4e70-9b66-51e46d6d4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_accuracy = [] # Array to save validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "602eb975-3bdf-48b9-8ba7-0be316b22de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_hid):\n",
    "        # initialize the weights\n",
    "        self.weight_1 = np.random.random([64, num_hid])  # w\n",
    "        self.bias_1 = np.random.random([1, num_hid])\n",
    "        self.weight_2 = np.random.random([num_hid, 10])  # v\n",
    "        self.bias_2 = np.random.random([1, 10])\n",
    "        self.num_hid = num_hid\n",
    "\n",
    "    def fit(self, train_x, train_y, valid_x, valid_y):\n",
    "        # learning rate\n",
    "        lr = 5e-3\n",
    "        # counter for recording the number of epochs without improvement\n",
    "        count = 0\n",
    "        best_valid_acc = 0\n",
    "\n",
    "        \"\"\"\n",
    "        Stop the training if there is no improvment over the best validation accuracy for more than 100 iterations\n",
    "        \"\"\"\n",
    "        while count <= 100:\n",
    "            # training with all samples (full-batch gradient descents)\n",
    "            # implement the forward pass\n",
    "            z = self.zero_node(self.get_hidden(train_x))\n",
    "            v = np.vstack((self.bias_2, self.weight_2))\n",
    "            y = np.array([softmax(z_i) for z_i in z@v])\n",
    "\n",
    "            # implement the backward pass (backpropagation)\n",
    "            # compute the gradients w.r.t. different parameters\n",
    "            delta_v = lr * ((train_y - y).T@z).T\n",
    "            delta_w = lr * (((train_y - y)@v.T * z *\n",
    "                             (np.ones((len(train_x), self.num_hid + 1)) - z)).T@self.zero_node(train_x)).T\n",
    "\n",
    "            # update the parameters based on sum of gradients for all training samples\n",
    "            self.weight_1 = self.weight_1 + delta_w[1:, 1:]\n",
    "            self.bias_1 = self.bias_1 + delta_w[0, 1:]\n",
    "            self.weight_2 = self.weight_2 + delta_v[1:, :]\n",
    "            self.bias_2 = self.bias_2 + delta_v[0, :]\n",
    "\n",
    "            # evaluate on validation data\n",
    "            predictions = self.predict(valid_x)\n",
    "            valid_acc = np.count_nonzero(\n",
    "                predictions.reshape(-1) == valid_y.reshape(-1))/len(valid_x)\n",
    "\n",
    "            # compare the current validation accuracy with the best one\n",
    "            if valid_acc > best_valid_acc:\n",
    "                best_valid_acc = valid_acc\n",
    "                count = 0\n",
    "            else:\n",
    "                count += 1\n",
    "        return best_valid_acc\n",
    "\n",
    "    def predict(self, x):\n",
    "        # generate the predicted probability of different classes\n",
    "        # convert class probability to predicted labels\n",
    "        z = self.zero_node(self.get_hidden(x))\n",
    "        v = np.vstack((self.bias_2, self.weight_2))\n",
    "        probabilities = np.array([softmax(z_i) for z_i in z@v])\n",
    "        return np.array([np.argmax(y_i) for y_i in probabilities])\n",
    "\n",
    "    def get_hidden(self, x):\n",
    "        # extract the intermediate features computed at the hidden layers (after applying activation function)\n",
    "        w = np.vstack((self.bias_1, self.weight_1))\n",
    "        return np.array([tanh(x_i) for x_i in self.zero_node(x)@w])\n",
    "\n",
    "    def params(self):\n",
    "        return self.weight_1, self.bias_1, self.weight_2, self.bias_2\n",
    "\n",
    "    def zero_node(self, x):\n",
    "        return np.hstack((np.ones(len(x))[..., None], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8af7c00-a1c1-4fb4-93ee-def3d9f86c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLP(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3a02e50-6611-4cb3-857d-795b3a7799ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,) (1000,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DINESH~1.AVM\\AppData\\Local\\Temp/ipykernel_8924/854298387.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcur_valid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\DINESH~1.AVM\\AppData\\Local\\Temp/ipykernel_8924/1293067235.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_x, train_y, valid_x, valid_y)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# implement the backward pass (backpropagation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# compute the gradients w.r.t. different parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mdelta_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             delta_w = lr * (((train_y - y)@v.T * z *\n\u001b[0;32m     31\u001b[0m                              (np.ones((len(train_x), self.num_hid + 1)) - z)).T@self.zero_node(train_x)).T\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,) (1000,10) "
     ]
    }
   ],
   "source": [
    "cur_valid_accuracy = clf.fit(train_x,train_y,valid_x,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307996c1-b913-4814-b4d5-f30d0c9e975e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23eec66f-ee3c-4609-89b4-1fca33618822",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,) (1000,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DINESH~1.AVM\\AppData\\Local\\Temp/ipykernel_8924/2443696842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_hid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_hid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# update the model based on training data, and record the best validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcur_valid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mvalid_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_valid_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation accuracy for %d hidden units is %.3f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_num_hid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcur_valid_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\DINESH~1.AVM\\AppData\\Local\\Temp/ipykernel_8924/1293067235.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_x, train_y, valid_x, valid_y)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# implement the backward pass (backpropagation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# compute the gradients w.r.t. different parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mdelta_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             delta_w = lr * (((train_y - y)@v.T * z *\n\u001b[0;32m     31\u001b[0m                              (np.ones((len(train_x), self.num_hid + 1)) - z)).T@self.zero_node(train_x)).T\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,) (1000,10) "
     ]
    }
   ],
   "source": [
    "candidate_num_hid = [4,8,16,20,24]\n",
    "valid_accuracy = []\n",
    "for i, num_hid in enumerate(candidate_num_hid):\n",
    "    # initialize the model\n",
    "    clf = MLP(num_hid=num_hid)\n",
    "    # update the model based on training data, and record the best validation accuracy\n",
    "    cur_valid_accuracy = clf.fit(train_x,train_y,valid_x,valid_y)\n",
    "    valid_accuracy.append(cur_valid_accuracy)\n",
    "    print('Validation accuracy for %d hidden units is %.3f' %(candidate_num_hid[i],cur_valid_accuracy))\n",
    "\n",
    "# select the best number of hidden unit and use it to train the model\n",
    "best_num_hid = candidate_num_hid[np.argmax(valid_accuracy)]\n",
    "clf = MLP(num_hid=best_num_hid)\n",
    "_ = clf.fit(train_x,train_y,valid_x,valid_y)\n",
    "\n",
    "# evaluate on test data\n",
    "predictions = clf.predict(test_x)\n",
    "accuracy = np.count_nonzero(predictions.reshape(-1)==test_y.reshape(-1))/len(test_x)\n",
    "\n",
    "print('Test accuracy with %d hidden units is %.3f' %(best_num_hid,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf8a22-c830-4102-b27f-a8443e73358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3547626-b1fe-468b-975e-59e007cbf4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
