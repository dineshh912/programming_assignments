{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: MapReduce\n",
    "\n",
    "While mapreduce is an important concept in large scale parallel systems it is possible to simulate it locally and on small practice problems.  To this end we provide a simple framework that allows you to run and test map/reduce functions below.  This assignment asks you to write the code for two, two-stage mapreduce problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def simple_mapreduce(map_fn, reduce_fn, kvin):\n",
    "    keyvalues = defaultdict(list)\n",
    "    for k, v in kvin:\n",
    "        for outk, outv in map_fn(k, v):\n",
    "            keyvalues[outk] += [outv]\n",
    "    kvout = []\n",
    "    for k, vs in keyvalues.items():\n",
    "        for outk, outv in reduce_fn(k, vs):\n",
    "            kvout += [(outk, outv)]\n",
    "    return kvout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "Some small speeches that are provided as an example dataset to play with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_dataset = [\n",
    "    (\"emmeline pankhurst\", \"\"\"You have left it to women in your land, the men of all civilised countries have left it to women, to work out their own salvation. That is the way in which we women of England are doing. Human life for us is sacred, but we say if any life is to be sacrificed it shall be ours; we won’t do it ourselves, but we will put the enemy in the position where they will have to choose between giving us freedom or giving us death.\"\"\"),\n",
    "    (\"gettysburg address\", \"\"\"Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.  But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\"\"\"),\n",
    "    (\"churchill address\", \"\"\"I have, myself, full confidence that if all do their duty, if nothing is neglected, and if the best arrangements are made, as they are being made, we shall prove ourselves once again able to defend our Island home, to ride out the storm of war, and to outlive the menace of tyranny, if necessary for years, if necessary alone. At any rate, that is what we are going to try to do. That is the resolve of His Majesty's Government-every man of them. That is the will of Parliament and the nation. The British Empire and the French Republic, linked together in their cause and in their need, will defend to the death their native soil, aiding each other like good comrades to the utmost of their strength. Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God's good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\"\"\"),\n",
    "    (\"mlk dream\", \"\"\"    I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification – one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.    I have a dream today.  I have a dream that one day every valley shall be exalted and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed and all flesh shall see it together.\"\"\"),\n",
    "    (\"hrc human rights\", \"\"\"‘If there is one message that echoes forth from this conference, let it be that human rights are women’s rights and women’s rights are human rights once and for all. Let us not forget that among those rights are the right to speak freely — and the right to be heard.’\"\"\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "\n",
    "This simple example takes the above data and counts the occurrence of words using a mapreduce algorithm\n",
    "Notice the use of yield instead of return.  yield is similar to return but for this purpose it allows us to return more than one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 51),\n",
       " ('and', 34),\n",
       " ('we', 27),\n",
       " ('to', 25),\n",
       " ('that', 23),\n",
       " ('of', 20),\n",
       " ('shall', 20),\n",
       " ('in', 17),\n",
       " ('have', 12),\n",
       " ('be', 12),\n",
       " ('a', 12),\n",
       " ('it', 11),\n",
       " ('is', 11),\n",
       " ('are', 10),\n",
       " ('for', 9),\n",
       " ('will', 8),\n",
       " ('not', 8),\n",
       " ('their', 7),\n",
       " ('us', 7),\n",
       " ('on', 7),\n",
       " ('--', 7),\n",
       " ('fight', 7),\n",
       " ('all', 6),\n",
       " ('if', 6),\n",
       " ('or', 6),\n",
       " ('with', 6),\n",
       " ('they', 5),\n",
       " ('our', 5),\n",
       " ('this', 5),\n",
       " ('can', 5),\n",
       " ('here', 5),\n",
       " ('i', 5),\n",
       " ('rights', 5),\n",
       " ('which', 4),\n",
       " ('do', 4),\n",
       " ('one', 4),\n",
       " ('human', 3),\n",
       " ('but', 3),\n",
       " ('any', 3),\n",
       " ('forth', 3),\n",
       " ('new', 3),\n",
       " ('nation,', 3),\n",
       " ('dedicated', 3),\n",
       " ('great', 3),\n",
       " ('so', 3),\n",
       " ('as', 3),\n",
       " ('who', 3),\n",
       " ('little', 3),\n",
       " ('what', 3),\n",
       " ('from', 3),\n",
       " ('people,', 3),\n",
       " ('defend', 3),\n",
       " ('its', 3),\n",
       " ('dream', 3),\n",
       " ('day', 3),\n",
       " ('right', 3),\n",
       " ('made', 3),\n",
       " ('left', 2),\n",
       " ('women', 2),\n",
       " ('men', 2),\n",
       " ('work', 2),\n",
       " ('out', 2),\n",
       " ('life', 2),\n",
       " ('say', 2),\n",
       " ('giving', 2),\n",
       " ('freedom', 2),\n",
       " ('conceived', 2),\n",
       " ('war,', 2),\n",
       " ('nation', 2),\n",
       " ('long', 2),\n",
       " ('dedicate', 2),\n",
       " ('those', 2),\n",
       " ('gave', 2),\n",
       " ('here,', 2),\n",
       " ('far', 2),\n",
       " ('power', 2),\n",
       " ('never', 2),\n",
       " ('forget', 2),\n",
       " ('these', 2),\n",
       " ('dead', 2),\n",
       " ('devotion', 2),\n",
       " ('cause', 2),\n",
       " ('full', 2),\n",
       " ('resolve', 2),\n",
       " ('by', 2),\n",
       " ('confidence', 2),\n",
       " ('made,', 2),\n",
       " ('once', 2),\n",
       " ('able', 2),\n",
       " ('island', 2),\n",
       " ('necessary', 2),\n",
       " ('his', 2),\n",
       " ('british', 2),\n",
       " ('empire', 2),\n",
       " ('good', 2),\n",
       " ('even', 2),\n",
       " ('large', 2),\n",
       " ('may', 2),\n",
       " ('growing', 2),\n",
       " ('there', 2),\n",
       " ('black', 2),\n",
       " ('boys', 2),\n",
       " ('girls', 2),\n",
       " ('white', 2),\n",
       " ('every', 2),\n",
       " ('places', 2),\n",
       " ('let', 2),\n",
       " ('women’s', 2),\n",
       " ('you', 1),\n",
       " ('your', 1),\n",
       " ('land,', 1),\n",
       " ('civilised', 1),\n",
       " ('countries', 1),\n",
       " ('women,', 1),\n",
       " ('own', 1),\n",
       " ('salvation.', 1),\n",
       " ('way', 1),\n",
       " ('england', 1),\n",
       " ('doing.', 1),\n",
       " ('sacred,', 1),\n",
       " ('sacrificed', 1),\n",
       " ('ours;', 1),\n",
       " ('won’t', 1),\n",
       " ('ourselves,', 1),\n",
       " ('put', 1),\n",
       " ('enemy', 1),\n",
       " ('position', 1),\n",
       " ('where', 1),\n",
       " ('choose', 1),\n",
       " ('between', 1),\n",
       " ('death.', 1),\n",
       " ('four', 1),\n",
       " ('score', 1),\n",
       " ('seven', 1),\n",
       " ('years', 1),\n",
       " ('ago', 1),\n",
       " ('fathers', 1),\n",
       " ('brought', 1),\n",
       " ('continent,', 1),\n",
       " ('liberty,', 1),\n",
       " ('proposition', 1),\n",
       " ('created', 1),\n",
       " ('equal.', 1),\n",
       " ('now', 1),\n",
       " ('engaged', 1),\n",
       " ('civil', 1),\n",
       " ('testing', 1),\n",
       " ('whether', 1),\n",
       " ('dedicated,', 1),\n",
       " ('endure.', 1),\n",
       " ('met', 1),\n",
       " ('battle-field', 1),\n",
       " ('war.', 1),\n",
       " ('come', 1),\n",
       " ('portion', 1),\n",
       " ('field,', 1),\n",
       " ('final', 1),\n",
       " ('resting', 1),\n",
       " ('place', 1),\n",
       " ('lives', 1),\n",
       " ('might', 1),\n",
       " ('live.', 1),\n",
       " ('altogether', 1),\n",
       " ('fitting', 1),\n",
       " ('proper', 1),\n",
       " ('should', 1),\n",
       " ('this.', 1),\n",
       " ('but,', 1),\n",
       " ('larger', 1),\n",
       " ('sense,', 1),\n",
       " ('consecrate', 1),\n",
       " ('hallow', 1),\n",
       " ('ground.', 1),\n",
       " ('brave', 1),\n",
       " ('men,', 1),\n",
       " ('living', 1),\n",
       " ('dead,', 1),\n",
       " ('struggled', 1),\n",
       " ('consecrated', 1),\n",
       " ('it,', 1),\n",
       " ('above', 1),\n",
       " ('poor', 1),\n",
       " ('add', 1),\n",
       " ('detract.', 1),\n",
       " ('world', 1),\n",
       " ('note,', 1),\n",
       " ('nor', 1),\n",
       " ('remember', 1),\n",
       " ('did', 1),\n",
       " ('here.', 1),\n",
       " ('living,', 1),\n",
       " ('rather,', 1),\n",
       " ('unfinished', 1),\n",
       " ('fought', 1),\n",
       " ('thus', 1),\n",
       " ('nobly', 1),\n",
       " ('advanced.', 1),\n",
       " ('rather', 1),\n",
       " ('task', 1),\n",
       " ('remaining', 1),\n",
       " ('before', 1),\n",
       " ('honored', 1),\n",
       " ('take', 1),\n",
       " ('increased', 1),\n",
       " ('last', 1),\n",
       " ('measure', 1),\n",
       " ('highly', 1),\n",
       " ('died', 1),\n",
       " ('vain', 1),\n",
       " ('under', 1),\n",
       " ('god,', 1),\n",
       " ('birth', 1),\n",
       " ('government', 1),\n",
       " ('perish', 1),\n",
       " ('earth.', 1),\n",
       " ('have,', 1),\n",
       " ('myself,', 1),\n",
       " ('duty,', 1),\n",
       " ('nothing', 1),\n",
       " ('neglected,', 1),\n",
       " ('best', 1),\n",
       " ('arrangements', 1),\n",
       " ('being', 1),\n",
       " ('prove', 1),\n",
       " ('ourselves', 1),\n",
       " ('again', 1),\n",
       " ('home,', 1),\n",
       " ('ride', 1),\n",
       " ('storm', 1),\n",
       " ('outlive', 1),\n",
       " ('menace', 1),\n",
       " ('tyranny,', 1),\n",
       " ('years,', 1),\n",
       " ('alone.', 1),\n",
       " ('at', 1),\n",
       " ('rate,', 1),\n",
       " ('going', 1),\n",
       " ('try', 1),\n",
       " ('do.', 1),\n",
       " (\"majesty's\", 1),\n",
       " ('government-every', 1),\n",
       " ('man', 1),\n",
       " ('them.', 1),\n",
       " ('parliament', 1),\n",
       " ('nation.', 1),\n",
       " ('french', 1),\n",
       " ('republic,', 1),\n",
       " ('linked', 1),\n",
       " ('together', 1),\n",
       " ('need,', 1),\n",
       " ('death', 1),\n",
       " ('native', 1),\n",
       " ('soil,', 1),\n",
       " ('aiding', 1),\n",
       " ('each', 1),\n",
       " ('other', 1),\n",
       " ('like', 1),\n",
       " ('comrades', 1),\n",
       " ('utmost', 1),\n",
       " ('strength.', 1),\n",
       " ('though', 1),\n",
       " ('tracts', 1),\n",
       " ('europe', 1),\n",
       " ('many', 1),\n",
       " ('old', 1),\n",
       " ('famous', 1),\n",
       " ('states', 1),\n",
       " ('fallen', 1),\n",
       " ('fall', 1),\n",
       " ('into', 1),\n",
       " ('grip', 1),\n",
       " ('gestapo', 1),\n",
       " ('odious', 1),\n",
       " ('apparatus', 1),\n",
       " ('nazi', 1),\n",
       " ('rule,', 1),\n",
       " ('flag', 1),\n",
       " ('fail.', 1),\n",
       " ('go', 1),\n",
       " ('end,', 1),\n",
       " ('france,', 1),\n",
       " ('seas', 1),\n",
       " ('oceans,', 1),\n",
       " ('strength', 1),\n",
       " ('air,', 1),\n",
       " ('island,', 1),\n",
       " ('whatever', 1),\n",
       " ('cost', 1),\n",
       " ('be,', 1),\n",
       " ('beaches,', 1),\n",
       " ('landing', 1),\n",
       " ('grounds,', 1),\n",
       " ('fields', 1),\n",
       " ('streets,', 1),\n",
       " ('hills;', 1),\n",
       " ('surrender,', 1),\n",
       " ('if,', 1),\n",
       " ('moment', 1),\n",
       " ('believe,', 1),\n",
       " ('part', 1),\n",
       " ('were', 1),\n",
       " ('subjugated', 1),\n",
       " ('starving,', 1),\n",
       " ('then', 1),\n",
       " ('beyond', 1),\n",
       " ('seas,', 1),\n",
       " ('armed', 1),\n",
       " ('guarded', 1),\n",
       " ('fleet,', 1),\n",
       " ('would', 1),\n",
       " ('carry', 1),\n",
       " ('struggle,', 1),\n",
       " ('until,', 1),\n",
       " (\"god's\", 1),\n",
       " ('time,', 1),\n",
       " ('world,', 1),\n",
       " ('might,', 1),\n",
       " ('steps', 1),\n",
       " ('rescue', 1),\n",
       " ('liberation', 1),\n",
       " ('old.', 1),\n",
       " ('down', 1),\n",
       " ('alabama,', 1),\n",
       " ('vicious', 1),\n",
       " ('racists,', 1),\n",
       " ('governor', 1),\n",
       " ('having', 1),\n",
       " ('lips', 1),\n",
       " ('dripping', 1),\n",
       " ('words', 1),\n",
       " ('interposition', 1),\n",
       " ('nullification', 1),\n",
       " ('–', 1),\n",
       " ('alabama', 1),\n",
       " ('join', 1),\n",
       " ('hands', 1),\n",
       " ('sisters', 1),\n",
       " ('brothers.', 1),\n",
       " ('today.', 1),\n",
       " ('valley', 1),\n",
       " ('exalted', 1),\n",
       " ('hill', 1),\n",
       " ('mountain', 1),\n",
       " ('low,', 1),\n",
       " ('rough', 1),\n",
       " ('plain,', 1),\n",
       " ('crooked', 1),\n",
       " ('straight,', 1),\n",
       " ('glory', 1),\n",
       " ('lord', 1),\n",
       " ('revealed', 1),\n",
       " ('flesh', 1),\n",
       " ('see', 1),\n",
       " ('together.', 1),\n",
       " ('‘if', 1),\n",
       " ('message', 1),\n",
       " ('echoes', 1),\n",
       " ('conference,', 1),\n",
       " ('all.', 1),\n",
       " ('among', 1),\n",
       " ('speak', 1),\n",
       " ('freely', 1),\n",
       " ('—', 1),\n",
       " ('heard.’', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k = title, v = text of speech\n",
    "def ex1_map1(k, v):\n",
    "    words = v.lower().split()  # simple tokenization, split by whitespaces\n",
    "    for word in words:\n",
    "        yield word, 1\n",
    "    \n",
    "# k = bigram, values = 1 for each bigram\n",
    "def ex1_reduce1(k, values):\n",
    "    yield k, sum(values)\n",
    "    \n",
    "sorted(simple_mapreduce(ex1_map1, ex1_reduce1, speech_dataset), key=lambda x: -x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Bigram statistics:\n",
    "Bigrams are two symbols that occur adjacently.  In this case the symbols are simply letters.  Below is a function `make_bigrams` that will turn a length of text into a list of bigrams.  Your job is to create a 2 step mapreduce function that first calculates the occurrence of bigrams and then in a second step calculates the average occurrence of bigrams that start with a particular letter.  Replace the `pass`'s with your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1defaf9b5c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mfirst_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_mapreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1_map1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_reduce1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mbigram_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_mapreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1_map2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_reduce2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_stage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6f38028ec831>\u001b[0m in \u001b[0;36msimple_mapreduce\u001b[0;34m(map_fn, reduce_fn, kvin)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mkeyvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkvin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0moutk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mkeyvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mkvout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# you may use this function that converts a string of text into bigrams THE -> th he\n",
    "def make_bigrams(text):\n",
    "    just_txt = [c.lower() for c in text if c in string.ascii_letters]\n",
    "    bigrams = [a + b for a,b in zip(just_txt[:-1], just_txt[1:])]\n",
    "    return bigrams\n",
    "\n",
    "#k = title, v = text\n",
    "def q1_map1(k, v):\n",
    "    bigrams = make_bigrams(v)\n",
    "    pass\n",
    "\n",
    "# k = bigram, values = 1 for each bigram\n",
    "def q1_reduce1(k, values):\n",
    "    pass\n",
    "\n",
    "# k = bigram, v the count for each bigram    \n",
    "def q1_map2(k, v):\n",
    "    pass\n",
    "    \n",
    "# k = the first letter of the bigram, v = a list of the # of bigrams that start with k  \n",
    "def q1_reduce2(k, values):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "first_stage = simple_mapreduce(q1_map1, q1_reduce1, speech_dataset)\n",
    "bigram_final = simple_mapreduce(q1_map2, q1_reduce2, first_stage)\n",
    "\n",
    "bigram_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_expected = [\n",
    " ('y*', 2.7058823529411766),\n",
    " ('o*', 10.826086956521738),\n",
    " ('u*', 6.090909090909091),\n",
    " ('h*', 17.923076923076923),\n",
    " ('a*', 14.95),\n",
    " ('v*', 14.25),\n",
    " ('e*', 19.82608695652174),\n",
    " ('l*', 9.0),\n",
    " ('f*', 6.5),\n",
    " ('t*', 17.05),\n",
    " ('i*', 13.166666666666666),\n",
    " ('w*', 9.555555555555555),\n",
    " ('m*', 6.777777777777778),\n",
    " ('n*', 11.6),\n",
    " ('r*', 9.952380952380953),\n",
    " ('d*', 8.105263157894736),\n",
    " ('c*', 7.2),\n",
    " ('s*', 8.428571428571429),\n",
    " ('k*', 1.4285714285714286),\n",
    " ('g*', 5.9375),\n",
    " ('b*', 5.333333333333333),\n",
    " ('p*', 4.222222222222222),\n",
    " ('q*', 1.0),\n",
    " ('j*', 1.0),\n",
    " ('z*', 1.0),\n",
    " ('x*', 1.0)\n",
    "]\n",
    "\n",
    "sorted(bigram_expected) == sorted(bigram_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: \n",
    "\n",
    "The input given to you describes a dataset of nodes connected to each other via edges. An example of such a network could be the Twitter follower network, in which the users denote nodes and two nodes are connected by an edge if one follows the other.\n",
    "\n",
    " * The **degree** of a node in a network is the number of connections it has to other nodes. \n",
    " * The **degree distribution** is the distribution of these degrees over the whole network.\n",
    "\n",
    "As an example, you can assume that the input you are given is an edgelist in the form of a table as shown below. This table shows pairs of edges connected to each other and thus capture the graph shown on the right:\n",
    "\n",
    "Source | Destination \n",
    "-------|-------------\n",
    " A | B\n",
    " A | C\n",
    " A | D \n",
    " B | C\n",
    "\n",
    " \n",
    " The degree distribution then is \n",
    " \n",
    " Degree | Count\n",
    " -------|-------\n",
    " 1      | 1\n",
    " 2      | 2\n",
    " 3      | 1\n",
    " \n",
    " As you can see, we have one nodes with degree 1 (which is D), two node with degree 2 (which is B and C), and one node with degree 3 (which is A). Thus, the degree distribution captures, for each value of degree, the number of nodes that have that degree.  Below you can see the network mapped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.axis(\"off\")\n",
    "plt.scatter( [0, 0, 1, 0], [1, 0, 0, -1], s=1000, marker='o')\n",
    "# Annotate with text + Arrow\n",
    "plt.plot([0, 0], [-1, 1], c=\"r\", zorder=-1)\n",
    "plt.plot([0, 1], [0, 0],  c=\"r\", zorder=-1)\n",
    "plt.plot([0, 1], [-1, 0], c=\"r\", zorder=-1)\n",
    "\n",
    "\n",
    "plt.annotate('A', xy=(0, 0), xytext=(0, 0), c=\"w\")\n",
    "plt.annotate('B', xy=(1, 0), xytext=(1, 0), c=\"w\")\n",
    "plt.annotate('C', xy=(0, -1), xytext=(0, -1), c=\"w\")\n",
    "plt.annotate('D', xy=(0, 1), xytext=(0, 1), c=\"w\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dataset = [\n",
    "    ('A', 'B'),\n",
    "    ('A', 'C'),\n",
    "    ('A', 'D'),\n",
    "    ('B', 'C'),\n",
    "]\n",
    "\n",
    "network_expected = [\n",
    "    (3, 1),\n",
    "    (2, 2),\n",
    "    (1, 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Q2: you are to write the body of the following functions: (replace the `pass`'s with your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=source node, v=destination node\n",
    "def q2_map1(k, v):\n",
    "    pass\n",
    "    \n",
    "def q2_reduce1(k, values):\n",
    "    pass\n",
    "    \n",
    "def q2_map2(k, v):\n",
    "    pass\n",
    "\n",
    "def q2_reduce2(k, values):\n",
    "    pass\n",
    "\n",
    "first_stage = simple_mapreduce(q2_map1, q2_reduce1, network_dataset)\n",
    "network_final = simple_mapreduce(q2_map2, q2_reduce2, first_stage)\n",
    "network_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(network_expected) == sorted(network_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
